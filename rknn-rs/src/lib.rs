#![allow(non_camel_case_types)]

use rknn_sys_rs as rknn_sys;

pub mod error;

/// Prelude module for RKNN (Rockchip Neural Network) related functionality.
///
/// This module contains commonly used types and functions for interacting with RKNN, making it convenient for use in other modules.
pub mod prelude {
    use super::rknn_sys;
    use std::{
        ffi::CString, mem, os::raw::c_void, ptr::null_mut, slice, str,
    };

    use bytemuck::Pod;
    pub use crate::error::Error;
    use crate::rkerr;

    /// RKNN tensor attributes.
    ///
    /// This struct describes the attributes of a tensor in an RKNN model, including dimensions, name, type, etc.
    #[derive(Debug, Copy, Clone)]
    pub struct _rknn_tensor_attr {
        /// Tensor index.
        pub index: u32,
        /// Number of dimensions.
        pub n_dims: u32,
        /// Tensor dimensions.
        pub dims: [u32; 16usize],
        /// Tensor name.
        pub name: [::std::os::raw::c_char; 256usize],
        /// Number of elements in the tensor.
        pub n_elems: u32,
        /// Size of the tensor in bytes.
        pub size: u32,
        /// Tensor format.
        pub fmt: rknn_sys::rknn_tensor_format,
        /// Tensor type.
        pub type_: rknn_sys::rknn_tensor_type,
        /// Tensor quantization type.
        pub qnt_type: rknn_sys::rknn_tensor_qnt_type,
        /// Quantization parameter fl.
        pub fl: i8,
        /// Quantization parameter zp.
        pub zp: i32,
        /// Quantization parameter scale.
        pub scale: f32,
        /// Width stride.
        pub w_stride: u32,
        /// Tensor size with stride.
        pub size_with_stride: u32,
        /// Whether to pass through.
        pub pass_through: u8,
        /// Height stride.
        pub h_stride: u32,
    }
    impl Default for _rknn_tensor_attr {
        fn default() -> Self {
            _rknn_tensor_attr {
                index: 0,
                n_dims: 0,
                dims: [0; 16],
                name: [0; 256],
                n_elems: 0,
                size: 0,
                fmt: rknn_sys::rknn_tensor_format::default(),
                type_: rknn_sys::rknn_tensor_type::default(),
                qnt_type: rknn_sys::rknn_tensor_qnt_type::default(),
                fl: 0,
                zp: 0,
                scale: 0.0,
                w_stride: 0,
                size_with_stride: 0,
                pass_through: 0,
                h_stride: 0,
            }
        }
    }

    /// RKNN input structure.
    ///
    /// This struct defines the input parameters for an RKNN model.
    #[derive(Debug, Copy, Clone)]
    pub struct _rknn_input {
        /// Input index.
        pub index: u32,
        /// Pointer to the input data buffer.
        pub buf: *mut ::std::os::raw::c_void,
        /// Size of the input data in bytes.
        pub size: u32,
        /// Whether to pass through.
        pub pass_through: u8,
        /// Input data type.
        pub type_: rknn_sys::rknn_tensor_type,
        /// Input data format.
        pub fmt: rknn_sys::rknn_tensor_format,
    }

    impl Default for _rknn_input {
        fn default() -> Self {
            _rknn_input {
                index: 0,
                buf: null_mut(),
                size: 0,
                pass_through: 1,
                fmt: rknn_sys::rknn_tensor_format::default(),
                type_: rknn_sys::rknn_tensor_type::default(),
            }
        }
    }

    /// Generic RKNN input structure.
    ///
    /// This struct provides a generic way to define inputs for an RKNN model.
    #[derive(Debug, Clone)]
    pub struct RknnInput<T> {
        /// Input index.
        pub index: usize,
        /// Input data buffer.
        pub buf: Vec<T>,
        /// Whether to pass through.
        pub pass_through: bool,
        /// Input data type.
        pub type_: RknnTensorType,
        /// Input data format.
        pub fmt: RknnTensorFormat,
    }

    impl<T> Default for RknnInput<T> {
        fn default() -> Self {
            Self {
                index: Default::default(),
                buf: Default::default(),
                pass_through: Default::default(),
                type_: RknnTensorType::Float32,
                fmt: RknnTensorFormat::Undefined,
            }
        }
    }

    /// RKNN tensor type.
    ///
    /// This enum defines the supported tensor data types in an RKNN model.
    #[derive(Debug, Copy, Clone)]
    pub enum RknnTensorType {
        /// 32-bit floating point.
        Float32 = 0,
        /// 16-bit floating point.
        Float16,
        /// 8-bit signed integer.
        Int8,
        /// 8-bit unsigned integer.
        Uint8,
        /// 16-bit signed integer.
        Int16,
        /// 16-bit unsigned integer.
        Uint16,
        /// 32-bit signed integer.
        Int32,
        /// 32-bit unsigned integer.
        Uint32,
        /// 64-bit signed integer.
        Int64,
        /// Boolean.
        Boolean,
        /// 4-bit integer.
        Int4,
        /// 16-bit brain floating point.
        BFloat16,
        /// Maximum type value (for boundary checking).
        TypeMax,
    }

    /// RKNN tensor format.
    ///
    /// This enum defines the supported tensor data formats in an RKNN model.
    #[derive(Debug, Copy, Clone)]
    pub enum RknnTensorFormat {
        /// NCHW format (batch-channel-height-width).
        NCHW = 0,
        /// NHWC format (batch-height-width-channel).
        NHWC,
        /// NC1HWC2 format.
        NC1HWC2,
        /// Undefined format.
        Undefined,
        /// Maximum format value (for boundary checking).
        FormatMax,
    }

    impl RknnTensorFormat {
        /// Convert an integer value to a tensor format.
        ///
        /// # Parameters
        ///
        /// - `input`: The integer value representing the format.
        ///
        /// # Returns
        ///
        /// The corresponding `RknnTensorFormat` value.
        pub fn from_int(input: u32) -> Self {
            match input {
                0 => RknnTensorFormat::NCHW,
                1 => RknnTensorFormat::NHWC,
                2 => RknnTensorFormat::NC1HWC2,
                3 => RknnTensorFormat::Undefined,
                _ => RknnTensorFormat::FormatMax,
            }
        }
    }

    /// Get the string representation of a tensor format.
    ///
    /// # Parameters
    ///
    /// - `fmt`: The tensor format.
    ///
    /// # Returns
    ///
    /// The string representation of the format.
    pub fn get_format_string(fmt: RknnTensorFormat) -> &'static str {
        match fmt {
            RknnTensorFormat::NCHW => "NCHW",
            RknnTensorFormat::NHWC => "NHWC",
            RknnTensorFormat::NC1HWC2 => "NC1HWC2",
            RknnTensorFormat::Undefined => "Undefined",
            RknnTensorFormat::FormatMax => "FormatMax",
        }
    }

    /// RKNN output structure.
    ///
    /// This struct holds the output data of an RKNN model and includes internal structures for resource release.
    /// It implements `Drop` to automatically release resources.
    pub struct RknnOutput<'a, T> {
        context: rknn_sys::rknn_context,
        memory: &'a [T],
        raw: rknn_sys::rknn_output,
    }

    impl<'a, T> Drop for RknnOutput<'a, T> {
        fn drop(&mut self) {
            unsafe {
                rknn_sys::rknn_outputs_release(self.context, 1, &mut self.raw);
            }
        }
    }

    impl<'a, T> std::ops::Deref for RknnOutput<'a, T> {
        type Target = [T];
        fn deref(&self) -> &Self::Target {
            self.memory
        }
    }

    impl<'a, T: std::fmt::Debug> std::fmt::Debug for RknnOutput<'a, T> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            f.debug_struct("RknnOutput")
                .field("context", &self.context)
                .field("memory", &self.memory)
                .finish()
        }
    }

    /// RKNN model.
    ///
    /// This struct encapsulates the context of an RKNN model, providing methods to load the model, set inputs, run inference, and retrieve outputs.
    /// 
    /// # Examples
    ///
    /// Hereâ€™s a simple example of how to use the `Rknn` struct:
    ///
    /// ```rust
    /// use std::path::Path;
    /// use crate::prelude::*;
    ///
    /// fn main() -> Result<(), Error> {
    ///     // Initialize the model
    ///     let model_path = Path::new("model.rknn");
    ///     let rknn = Rknn::rknn_init(model_path)?;
    ///
    ///     // Set input
    ///     let mut input = RknnInput::<f32> {
    ///         index: 0,
    ///         buf: vec![0.0; 100],
    ///         pass_through: false,
    ///         type_: RknnTensorType::Float32,
    ///         fmt: RknnTensorFormat::NCHW,
    ///     };
    ///     rknn.input_set(&mut input)?;
    ///
    ///     // Run the model
    ///     rknn.run()?;
    ///
    ///     // Get output
    ///     let output = rknn.outputs_get::<f32>()?;
    ///     println!("Output: {:?}", output);
    ///
    ///     Ok(())
    /// }
    /// ```
    #[doc = "Rknn model"]
    #[derive(Debug)]
    pub struct Rknn {
        context: rknn_sys::rknn_context,
    }

    impl Drop for Rknn {
        fn drop(&mut self) {
            if self.context != 0 {
                unsafe { rknn_sys::rknn_destroy(self.context) };
            }
        }
    }
    impl Rknn {
        /// Initialize an RKNN model.
        ///
        /// # Parameters
        ///
        /// - `model_path`: The path to the model file.
        ///
        /// # Returns
        ///
        /// If successful, returns an `Rknn` instance; otherwise, returns an `Error`.
        pub fn rknn_init<P: AsRef<std::path::Path>>(model_path: P) -> Result<Self, Error> {
            let mut ret = Rknn { context: 0 };
            let path_str = model_path.as_ref().to_string_lossy();
            let path_cstr = CString::new(path_str.as_ref())
                .map_err(|e| Error(format!("Invalid model path: {}", e)))?;

            unsafe {
                let result = rknn_sys::rknn_init(
                    &mut ret.context,
                    path_cstr.as_ptr() as *mut std::ffi::c_void,
                    0,
                    0,
                    null_mut(),
                );
                if result != 0 {
                    return rkerr!("rknn_init faild.", result);
                }
            }
            Ok(ret)
        }

        /// Set the model's input.
        ///
        /// # Parameters
        ///
        /// - `input`: A mutable reference to the generic input structure `RknnInput<T>`.
        ///
        /// # Returns
        ///
        /// If successful, returns `Ok(()`; otherwise, returns an `Error`.
        pub fn input_set<T: Pod + 'static>(&self, input: &mut RknnInput<T>) -> Result<(), Error> {
            let total_bytes = (input.buf.len() * mem::size_of::<T>()) as u32;
            let mut c_input = rknn_sys::rknn_input {
                index: input.index as u32,
                buf: input.buf.as_mut_ptr() as *mut c_void,
                size: total_bytes,
                pass_through: if input.pass_through { 1 } else { 0 },
                type_: input.type_ as u32,
                fmt: input.fmt as u32,
            };

            let result = unsafe { rknn_sys::rknn_inputs_set(self.context, 1, &mut c_input) };
            if result != 0 {
                return rkerr!("rknn_inputs_set failed.", result);
            }
            Ok(())
        }

        /// Run the RKNN model.
        ///
        /// # Returns
        ///
        /// If successful, returns `Ok(()`; otherwise, returns an `Error`.
        pub fn run(&self) -> Result<(), Error> {
            let result = unsafe { rknn_sys::rknn_run(self.context, null_mut()) };
            if result != 0 {
                return rkerr!("rknn_run faild.", result);
            }
            Ok(())
        }

        /// Retrieve input/output information of the model.
        ///
        /// This method queries the model's input and output tensor attributes and prints them.
        ///
        /// # Returns
        ///
        /// If successful, returns `Ok(()`; otherwise, returns an `Error`.
        pub fn info(&self) -> Result<(), Error> {
            let mut io_num = rknn_sys::_rknn_input_output_num {
                n_input: 0,
                n_output: 0,
            };

            let result = unsafe {
                rknn_sys::rknn_query(
                    self.context,
                    rknn_sys::_rknn_query_cmd_RKNN_QUERY_IN_OUT_NUM,
                    &mut io_num as *mut rknn_sys::_rknn_input_output_num as *mut std::ffi::c_void,
                    mem::size_of::<rknn_sys::_rknn_input_output_num>() as u32,
                )
            };

            if result != 0 {
                return rkerr!("rknn_query  faild.", result);
            }
	        println!("Model has {} inputs, {} outputs", io_num.n_input, io_num.n_output);
	        let mut raw_attr = [0u8; 512];

            for i in 0..io_num.n_input {
		        raw_attr.fill(0);
                raw_attr[0..4].copy_from_slice(&(i as u32).to_le_bytes());
                //let mut rknn_tensor_attr = _rknn_tensor_attr::default();
                //rknn_tensor_attr.index = i;
                let result = unsafe {
                    rknn_sys::rknn_query(
                        self.context,
                        rknn_sys::_rknn_query_cmd_RKNN_QUERY_INPUT_ATTR,
			            raw_attr.as_mut_ptr() as *mut std::ffi::c_void,
                        raw_attr.len() as u32,
                        //&mut rknn_tensor_attr as *mut _rknn_tensor_attr as *mut std::ffi::c_void,
                        //mem::size_of::<rknn_sys::_rknn_tensor_attr>() as u32,
                    )
                };
                //println!("Input {}: {:?}", i, rknn_tensor_attr);
                if result != 0 {
                    return rkerr!("rknn_query faild.", result);
                }
		        Self::parse_and_print_tensor_attr(&raw_attr, i as i32, "Input");
            }

            for i in 0..io_num.n_output {
		        raw_attr.fill(0);
                raw_attr[0..4].copy_from_slice(&(i as u32).to_le_bytes());
                //let mut rknn_tensor_attr = _rknn_tensor_attr::default();
                //rknn_tensor_attr.index = i;
                let result = unsafe {
                    rknn_sys::rknn_query(
                        self.context,
                        rknn_sys::_rknn_query_cmd_RKNN_QUERY_OUTPUT_ATTR,
			            raw_attr.as_mut_ptr() as *mut std::ffi::c_void,
                        raw_attr.len() as u32,
                        //&mut rknn_tensor_attr as *mut _rknn_tensor_attr as *mut std::ffi::c_void,
                        //mem::size_of::<rknn_sys::_rknn_tensor_attr>() as u32,
                    )
                };
                //println!("Output {}: {:?}", i, rknn_tensor_attr);
                if result != 0 {
                    return rkerr!("rknn_query faild.", result);
                }
		        Self::parse_and_print_tensor_attr(&raw_attr, i as i32, "Output");
            }

            Ok(())
        }

	    fn parse_and_print_tensor_attr(raw: &[u8], idx: i32, kind: &str) {
            let _index = u32::from_le_bytes(raw[0..4].try_into().unwrap());
            let n_dims = u32::from_le_bytes(raw[4..8].try_into().unwrap());

            let mut dims = Vec::new();
            for d in 0..n_dims as usize {
                let offset = 8 + d * 4;
                let dim = u32::from_le_bytes(raw[offset..offset + 4].try_into().unwrap());
                dims.push(dim);
            }

            let name_offset = 8 + 16 * 4;
            let name_bytes = &raw[name_offset..name_offset + 256];
            let name = std::str::from_utf8(
                &name_bytes[..name_bytes
                    .iter()
                    .position(|&b| b == 0)
                    .unwrap_or(256)])
                .unwrap_or("<invalid>");
            
            let elems_offset = name_offset + 256;
            let n_elems = u32::from_le_bytes(raw[elems_offset..elems_offset + 4].try_into().unwrap());
            let size = u32::from_le_bytes(raw[elems_offset + 4..elems_offset + 8].try_into().unwrap());

            println!("{} {}: name='{}', dims={:?}, n_elems={}, size={} bytes", kind, idx, name, dims, n_elems, size);
        }

        /// Get the model's output (raw version).
        ///
        /// This method returns raw output data (zero-copy) and delegates resource management to `RknnOutput<T>`.
        /// The returned `RknnOutput` automatically releases resources when dropped.
        ///
        /// # Returns
        ///
        /// If successful, returns a `RknnOutput<'a, T>`; otherwise, returns an `Error`.
        pub fn outputs_get<'a, T: Pod + Copy + 'static>(&'a self) -> Result<RknnOutput<'a, T>, Error> {
            let mut out = rknn_sys::rknn_output {
                want_float: 1,
                is_prealloc: 0,
                index: 0,
                buf: std::ptr::null_mut(),
                size: 0,
            };
            
            let result =
                unsafe { rknn_sys::rknn_outputs_get(self.context, 1, &mut out, std::ptr::null_mut()) };
            if result != 0 {
                return rkerr!("rknn_outputs_get faild.", result);
            }
            let element_size = mem::size_of::<T>();
            let num_elements = out.size as usize / element_size;
            let t_slice = unsafe { slice::from_raw_parts(out.buf as *const T, num_elements) };
            
            Ok(RknnOutput {
                context: self.context,
                memory: t_slice,
                raw: out,
            })
        }
    }
}
